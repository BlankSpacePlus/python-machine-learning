&emsp;&emsp;在真实的场景中，不均衡的分类到处可见，比如大多数访客都不会单击“购买”按钮，大多数用户都不会付费成为“VIP”，有些癌症或遗传病也是十分罕见的。因此，处理不均衡分类就称为机器学习的一个常见任务。
&emsp;&emsp;对此，最好的解决方案是收集更多的观观察值——尤其是占少数的分类的观察值。可惜的是，这可能很难做到，所以我们需要求助于其他手段。
&emsp;&emsp;次优的解决方案是选择更适用于评估不均衡数据的标准。准确率常常被作为评估模型性能的标准，但用准确率来评估不均衡分类是不合适的。例如，如果样本中只有0.5%的人得了某种罕见的癌症，那么即使我们的模型预测没有人会得这种癌症，准确率也只能达到99.5%。很明显，这也不是我们想要的。一些更有效的评估标准，如混淆矩阵、精确度、召回率、F1值以及ROC曲线都是值得学习的。（题外话：记得HIT王宏志教授说ML流程中研究最弱的是模型评估 ~~（如果我没记错的话）~~ ）
&emsp;&emsp;第三个解决方案是在一些分类器模型中使用分类权重参数，这样就能针对不均衡的分类来调整算法。scikit-learn的很多分类器都有class_weight参数，便于使用。
&emsp;&emsp;第四个方案和第五个方案是相关的：下采样和上采样。在下采样中，需要从占多数的分类中创建一个子集，其观察之数量与占少数的分类的观察值数量相等。在上采样中，采用有放回的方式对占少数的分类重复采样，一次创建与占多数的分类有相同数量观察值的数据集。到底是下采样还是上采样，需要根据实际场景做决定。通常情况下，应该同时尝试两种方法，看看哪种效果更好。
